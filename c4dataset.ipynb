{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an experiment to extend the original dataset using the c4 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\27gur\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "en = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
    "ru = load_dataset(\"allenai/c4\", \"ru\", split=\"train\", streaming=True)\n",
    "es = load_dataset(\"allenai/c4\", \"es\", split=\"train\", streaming=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33946it [00:20, 1654.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# take 20000 samples from en which have less than 200 words\n",
    "en_samples = []\n",
    "for sample in tqdm(en):\n",
    "    if len(sample[\"text\"].split()) < 300:\n",
    "        en_samples.append(sample[\"text\"])\n",
    "    if len(en_samples) == 20000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15047it [00:27, 548.44it/s] \n"
     ]
    }
   ],
   "source": [
    "# take 7000 samples from ru which have less than 200 words\n",
    "ru_samples = []\n",
    "for sample in tqdm(ru):\n",
    "    if len(sample[\"text\"].split()) < 300:\n",
    "        ru_samples.append(sample[\"text\"])\n",
    "    if len(ru_samples) == 9000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19149it [00:07, 2631.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# take 7000 samples from es which have less than 200 words\n",
    "es_samples = []\n",
    "for sample in tqdm(es):\n",
    "    if len(sample[\"text\"].split()) < 300:\n",
    "        es_samples.append(sample[\"text\"])\n",
    "    if len(es_samples) == 9000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last 2000 samples from each language\n",
    "en_samples = en_samples[-2000:]\n",
    "ru_samples = ru_samples[-2000:]\n",
    "es_samples = es_samples[-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    # remove urls\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    # remove emails\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    # remove whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # remove \\n\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6379it [00:07, 903.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5552it [00:03, 1559.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5444it [00:06, 798.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6833it [00:07, 908.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5523it [00:05, 1012.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6787it [00:10, 674.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5985it [00:07, 832.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5960it [00:03, 1737.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6301it [00:07, 793.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19794it [00:28, 683.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5961it [00:03, 1611.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "languages = ['de', 'en', 'uk', 'es', 'nl', 'ca', 'ru', 'pt', 'ar', 'zh', 'cs']\n",
    "new_test_df = pd.DataFrame(columns=[\"text\", \"label\", \"multi_label\", \"split\", \"language\", \"length\", \"source\" ])\n",
    "# get 2000 samples from each language and create a dataframe\n",
    "for lang in languages:\n",
    "    dataset = load_dataset(\"allenai/c4\", lang, split=\"validation\", streaming=True)\n",
    "    print(lang)\n",
    "    samples = []\n",
    "    for sample in tqdm(dataset):\n",
    "        sample = preprocess_text(sample[\"text\"])\n",
    "        if len(sample.split()) < 300 and len(sample.split()) > 100:\n",
    "            samples.append(sample)\n",
    "        if len(samples) == 2000:\n",
    "            break\n",
    "    all = []\n",
    "    for sample in samples:\n",
    "        all.append([sample, 0, \"human\", \"test\", lang, len(sample.split()), \"c4\"])\n",
    "    df = pd.DataFrame(all, columns=[\"text\", \"label\", \"multi_label\", \"split\", \"language\", \"length\", \"source\" ])\n",
    "    new_test_df = pd.concat([new_test_df, df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text           0\n",
      "label          0\n",
      "multi_label    0\n",
      "split          0\n",
      "language       0\n",
      "length         0\n",
      "source         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "print(new_test_df.isnull().sum())\n",
    "\n",
    "# drop null values\n",
    "new_test_df = new_test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df.to_csv(\"dataset/c4_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.concat([new_test_df, pd.read_csv(\"dataset/multic4.csv\")])\n",
    "final_dataset.to_csv(\"dataset/multic4-new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df label\n",
      "1    26059\n",
      "0    25236\n",
      "Name: count, dtype: int64\n",
      "train_df label\n",
      "1    40030\n",
      "0    38753\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_df\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# graph of the number of samples as label 0 or 1 in test and train\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass distribution in test set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "train_df = final_dataset[final_dataset[\"split\"] == \"train\"]\n",
    "test_df = final_dataset[final_dataset[\"split\"] == \"test\"]\n",
    "\n",
    "# number of samples as label 0 or 1 in test and train\n",
    "print(\"test_df\", test_df['label'].value_counts())\n",
    "print(\"train_df\", train_df['label'].value_counts())\n",
    "\n",
    "# graph of the number of samples as label 0 or 1 in test and train\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_df['label'].value_counts().plot(kind='bar')\n",
    "plt.title('class distribution in test set')\n",
    "plt.show()\n",
    "\n",
    "train_df['label'].value_counts().plot(kind='bar')\n",
    "plt.title('class distribution in train set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257.41263636363635"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.3187 125.82485714285714 144.264\n"
     ]
    }
   ],
   "source": [
    "# average number of words\n",
    "en_words = sum([len(x.split()) for x in en_samples])\n",
    "ru_words = sum([len(x.split()) for x in ru_samples])\n",
    "es_words = sum([len(x.split()) for x in es_samples])\n",
    "\n",
    "en_words = en_words / len(en_samples)\n",
    "ru_words = ru_words / len(ru_samples)\n",
    "es_words = es_words / len(es_samples)\n",
    "\n",
    "print(en_words, ru_words, es_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.read_csv(\"dataset/dataset_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>split</th>\n",
       "      <th>language</th>\n",
       "      <th>length</th>\n",
       "      <th>source</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>question_mark_count</th>\n",
       "      <th>exclamation_mark_count</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>first_person_pronoun_count</th>\n",
       "      <th>person_entity_count</th>\n",
       "      <th>date_entity_count</th>\n",
       "      <th>uniqueness_bigram</th>\n",
       "      <th>uniqueness_trigram</th>\n",
       "      <th>syntax_variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der Ausbruch des Coronavirus hat die Entwicklu...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>test</td>\n",
       "      <td>de</td>\n",
       "      <td>174</td>\n",
       "      <td>MULTITuDE_MassiveSumm_spiegel</td>\n",
       "      <td>199.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-272.022170</td>\n",
       "      <td>11.156030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.979695</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Azar was officially sworn in as the U.S. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>57</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "      <td>70.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-186.793214</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Європейський союз вимагає зупинити розтрату ко...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>test</td>\n",
       "      <td>uk</td>\n",
       "      <td>105</td>\n",
       "      <td>MULTITuDE_MassiveSumm_interfax</td>\n",
       "      <td>130.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-269.236538</td>\n",
       "      <td>11.015385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yesterday, hundreds of Zambian university stud...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>254</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "      <td>292.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-231.229869</td>\n",
       "      <td>11.440100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In a narrow and highly watched vote, the US Se...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>416</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "      <td>476.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-224.855788</td>\n",
       "      <td>13.160504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.871579</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       multi_label  \\\n",
       "0  Der Ausbruch des Coronavirus hat die Entwicklu...      1  text-davinci-003   \n",
       "1  Alex Azar was officially sworn in as the U.S. ...      1  text-davinci-003   \n",
       "2  Європейський союз вимагає зупинити розтрату ко...      1     gpt-3.5-turbo   \n",
       "3  Yesterday, hundreds of Zambian university stud...      1  text-davinci-003   \n",
       "4  In a narrow and highly watched vote, the US Se...      1             gpt-4   \n",
       "\n",
       "   split language  length                          source  word_count  \\\n",
       "0   test       de     174   MULTITuDE_MassiveSumm_spiegel       199.0   \n",
       "1  train       en      57   MULTITuDE_MassiveSumm_voanews        70.0   \n",
       "2   test       uk     105  MULTITuDE_MassiveSumm_interfax       130.0   \n",
       "3  train       en     254   MULTITuDE_MassiveSumm_voanews       292.0   \n",
       "4  train       en     416   MULTITuDE_MassiveSumm_voanews       476.0   \n",
       "\n",
       "   unique_word_count  char_count  ...  question_mark_count  \\\n",
       "0              118.0      1067.0  ...                  0.0   \n",
       "1               54.0       311.0  ...                  0.0   \n",
       "2               82.0       691.0  ...                  0.0   \n",
       "3              149.0      1419.0  ...                  0.0   \n",
       "4              242.0      2259.0  ...                  0.0   \n",
       "\n",
       "   exclamation_mark_count  flesch_reading_ease  gunning_fog_index  \\\n",
       "0                     0.0          -272.022170          11.156030   \n",
       "1                     1.0          -186.793214           8.714286   \n",
       "2                     0.0          -269.236538          11.015385   \n",
       "3                     0.0          -231.229869          11.440100   \n",
       "4                     0.0          -224.855788          13.160504   \n",
       "\n",
       "   first_person_pronoun_count  person_entity_count  date_entity_count  \\\n",
       "0                         0.0                  0.0                0.0   \n",
       "1                         0.0                  5.0                2.0   \n",
       "2                         0.0                  0.0                0.0   \n",
       "3                         1.0                  1.0                1.0   \n",
       "4                         1.0                  2.0                2.0   \n",
       "\n",
       "   uniqueness_bigram  uniqueness_trigram  syntax_variety  \n",
       "0           0.904040            0.979695            12.0  \n",
       "1           1.000000            1.000000            11.0  \n",
       "2           0.860465            0.929688            14.0  \n",
       "3           0.876289            0.965517            13.0  \n",
       "4           0.871579            0.974684            15.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns=[\"text\", \"label\", \"multi_label\", \"split\", \"language\", \"length\", \"source\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add en samples\n",
    "all_en = []\n",
    "for sample in en_samples:\n",
    "    all_en.append([sample, 0, \"human\", \"train\", \"en\", len(sample.split()), \"c4\"])\n",
    "\n",
    "# add ru samples\n",
    "all_ru = []\n",
    "for sample in ru_samples:\n",
    "    all_ru.append([sample, 0, \"human\", \"train\", \"ru\", len(sample.split()), \"c4\"])\n",
    "\n",
    "# add es samples\n",
    "all_es = []\n",
    "for sample in es_samples:\n",
    "    all_es.append([sample, 0, \"human\", \"train\", \"es\", len(sample.split()), \"c4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = pd.DataFrame(all_en, columns=[\"text\", \"label\", \"multi_label\", \"split\", \"language\", \"length\", \"source\"])\n",
    "df_es = pd.DataFrame(all_es, columns=[\"text\", \"label\", \"multi_label\", \"split\", \"language\", \"length\", \"source\"])\n",
    "df_ru = pd.DataFrame(all_ru, columns=[\"text\", \"label\", \"multi_label\", \"split\", \"language\", \"length\", \"source\"])\n",
    "\n",
    "new_df = pd.concat([df_en, df_ru, df_es], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>split</th>\n",
       "      <th>language</th>\n",
       "      <th>length</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beginners BBQ Class Taking Place in Missoula!\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>130</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foil plaid lycra and spandex shortall with met...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>29</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many backlinks per day for new site?\\nDisc...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>187</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Denver Board of Education opened the 2017-...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>164</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANGALORE CY JUNCTION SBC to GONDIA JUNCTION G...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>63</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33995</th>\n",
       "      <td>Neumáticos 315/30 R18 » ENTREGA GRATIS » Opone...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>68</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33996</th>\n",
       "      <td>Carlos Morales archivos - Seguros TV Blog Segu...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>83</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33997</th>\n",
       "      <td>Aniversarios de Empresa Castro-Urdiales - Mari...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>140</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33998</th>\n",
       "      <td>04 de July del 2017 a las 21:29 -\\nTres comisi...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>233</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33999</th>\n",
       "      <td>Se inició la entrega de viviendas para 1.200 f...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>135</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label multi_label  \\\n",
       "0      Beginners BBQ Class Taking Place in Missoula!\\...      0       human   \n",
       "1      Foil plaid lycra and spandex shortall with met...      0       human   \n",
       "2      How many backlinks per day for new site?\\nDisc...      0       human   \n",
       "3      The Denver Board of Education opened the 2017-...      0       human   \n",
       "4      BANGALORE CY JUNCTION SBC to GONDIA JUNCTION G...      0       human   \n",
       "...                                                  ...    ...         ...   \n",
       "33995  Neumáticos 315/30 R18 » ENTREGA GRATIS » Opone...      0       human   \n",
       "33996  Carlos Morales archivos - Seguros TV Blog Segu...      0       human   \n",
       "33997  Aniversarios de Empresa Castro-Urdiales - Mari...      0       human   \n",
       "33998  04 de July del 2017 a las 21:29 -\\nTres comisi...      0       human   \n",
       "33999  Se inició la entrega de viviendas para 1.200 f...      0       human   \n",
       "\n",
       "       split language  length source  \n",
       "0      train       en     130     c4  \n",
       "1      train       en      29     c4  \n",
       "2      train       en     187     c4  \n",
       "3      train       en     164     c4  \n",
       "4      train       en      63     c4  \n",
       "...      ...      ...     ...    ...  \n",
       "33995  train       es      68     c4  \n",
       "33996  train       es      83     c4  \n",
       "33997  train       es     140     c4  \n",
       "33998  train       es     233     c4  \n",
       "33999  train       es     135     c4  \n",
       "\n",
       "[34000 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproces the text in the new_df\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    # remove urls\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    # remove emails\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    # remove whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # remove \\n\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    return text\n",
    "\n",
    "new_df[\"text\"] = new_df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the length column\n",
    "new_df[\"length\"] = new_df[\"text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.41838235294117\n"
     ]
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnew_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "new_df['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitude = pd.read_csv(\"dataset/multitude.csv\")\n",
    "multic4 = pd.concat([multitude, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"dataset/c4train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text           0\n",
      "label          0\n",
      "multi_label    0\n",
      "split          0\n",
      "language       0\n",
      "length         0\n",
      "source         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count nan values\n",
    "print(multic4.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "multic4.to_csv(\"dataset/multic4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text           0\n",
      "label          0\n",
      "multi_label    0\n",
      "split          0\n",
      "language       0\n",
      "length         0\n",
      "source         0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for none values\n",
    "multic4 = pd.read_csv(\"dataset/multic4.csv\")\n",
    "\n",
    "print(multic4.isnull().sum())\n",
    "# check for duplicates\n",
    "print(multic4.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text           0\n",
      "label          0\n",
      "multi_label    0\n",
      "split          0\n",
      "language       0\n",
      "length         0\n",
      "source         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove null values\n",
    "multic4 = multic4.dropna()\n",
    "# remove duplicates\n",
    "multic4 = multic4.drop_duplicates()\n",
    "print(multic4.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>split</th>\n",
       "      <th>language</th>\n",
       "      <th>length</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der Ausbruch des Coronavirus hat die Entwicklu...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>test</td>\n",
       "      <td>de</td>\n",
       "      <td>174</td>\n",
       "      <td>MULTITuDE_MassiveSumm_spiegel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Azar was officially sworn in as the U.S. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>57</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Європейський союз вимагає зупинити розтрату ко...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>test</td>\n",
       "      <td>uk</td>\n",
       "      <td>105</td>\n",
       "      <td>MULTITuDE_MassiveSumm_interfax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yesterday, hundreds of Zambian university stud...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>254</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In a narrow and highly watched vote, the US Se...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>416</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label       multi_label  \\\n",
       "0  Der Ausbruch des Coronavirus hat die Entwicklu...      1  text-davinci-003   \n",
       "1  Alex Azar was officially sworn in as the U.S. ...      1  text-davinci-003   \n",
       "2  Європейський союз вимагає зупинити розтрату ко...      1     gpt-3.5-turbo   \n",
       "3  Yesterday, hundreds of Zambian university stud...      1  text-davinci-003   \n",
       "4  In a narrow and highly watched vote, the US Se...      1             gpt-4   \n",
       "\n",
       "   split language  length                          source  \n",
       "0   test       de     174   MULTITuDE_MassiveSumm_spiegel  \n",
       "1  train       en      57   MULTITuDE_MassiveSumm_voanews  \n",
       "2   test       uk     105  MULTITuDE_MassiveSumm_interfax  \n",
       "3  train       en     254   MULTITuDE_MassiveSumm_voanews  \n",
       "4  train       en     416   MULTITuDE_MassiveSumm_voanews  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multic4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "multic4.to_csv(\"dataset/multic4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>split</th>\n",
       "      <th>language</th>\n",
       "      <th>length</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der Ausbruch des Coronavirus hat die Entwicklu...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>test</td>\n",
       "      <td>de</td>\n",
       "      <td>174</td>\n",
       "      <td>MULTITuDE_MassiveSumm_spiegel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Azar was officially sworn in as the U.S. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>57</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Європейський союз вимагає зупинити розтрату ко...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>test</td>\n",
       "      <td>uk</td>\n",
       "      <td>105</td>\n",
       "      <td>MULTITuDE_MassiveSumm_interfax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yesterday, hundreds of Zambian university stud...</td>\n",
       "      <td>1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>254</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In a narrow and highly watched vote, the US Se...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>train</td>\n",
       "      <td>en</td>\n",
       "      <td>416</td>\n",
       "      <td>MULTITuDE_MassiveSumm_voanews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108076</th>\n",
       "      <td>neumáticos 315/30 r18 » entrega gratis » opone...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>68</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108077</th>\n",
       "      <td>carlos morales archivos - seguros tv blog segu...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>83</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108078</th>\n",
       "      <td>aniversarios de empresa castro-urdiales - mari...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>140</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108079</th>\n",
       "      <td>04 de july del 2017 a las 21:29 - tres comisio...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>233</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108080</th>\n",
       "      <td>se inició la entrega de viviendas para 1.200 f...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>es</td>\n",
       "      <td>135</td>\n",
       "      <td>c4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108078 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "0       Der Ausbruch des Coronavirus hat die Entwicklu...      1   \n",
       "1       Alex Azar was officially sworn in as the U.S. ...      1   \n",
       "2       Європейський союз вимагає зупинити розтрату ко...      1   \n",
       "3       Yesterday, hundreds of Zambian university stud...      1   \n",
       "4       In a narrow and highly watched vote, the US Se...      1   \n",
       "...                                                   ...    ...   \n",
       "108076  neumáticos 315/30 r18 » entrega gratis » opone...      0   \n",
       "108077  carlos morales archivos - seguros tv blog segu...      0   \n",
       "108078  aniversarios de empresa castro-urdiales - mari...      0   \n",
       "108079  04 de july del 2017 a las 21:29 - tres comisio...      0   \n",
       "108080  se inició la entrega de viviendas para 1.200 f...      0   \n",
       "\n",
       "             multi_label  split language  length  \\\n",
       "0       text-davinci-003   test       de     174   \n",
       "1       text-davinci-003  train       en      57   \n",
       "2          gpt-3.5-turbo   test       uk     105   \n",
       "3       text-davinci-003  train       en     254   \n",
       "4                  gpt-4  train       en     416   \n",
       "...                  ...    ...      ...     ...   \n",
       "108076             human  train       es      68   \n",
       "108077             human  train       es      83   \n",
       "108078             human  train       es     140   \n",
       "108079             human  train       es     233   \n",
       "108080             human  train       es     135   \n",
       "\n",
       "                                source  \n",
       "0        MULTITuDE_MassiveSumm_spiegel  \n",
       "1        MULTITuDE_MassiveSumm_voanews  \n",
       "2       MULTITuDE_MassiveSumm_interfax  \n",
       "3        MULTITuDE_MassiveSumm_voanews  \n",
       "4        MULTITuDE_MassiveSumm_voanews  \n",
       "...                                ...  \n",
       "108076                              c4  \n",
       "108077                              c4  \n",
       "108078                              c4  \n",
       "108079                              c4  \n",
       "108080                              c4  \n",
       "\n",
       "[108078 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multic4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.at[index, 'word_count'] = features.word_count\n",
    "    results.at[index, 'unique_word_count'] = features.unique_word_count\n",
    "    results.at[index, 'char_count'] = features.char_count\n",
    "    results.at[index, 'avg_word_length'] = features.avg_word_length\n",
    "    results.at[index, 'ttr'] = features.ttr\n",
    "    results.at[index, 'hapax_legomenon'] = features.hapax_legomenon\n",
    "    results.at[index, 'sentence_count'] = features.sentence_count\n",
    "    results.at[index, 'avg_sentence_length'] = features.avg_sentence_length\n",
    "    results.at[index, 'avg_sentence_complexity'] = features.avg_sentence_complexity\n",
    "    results.at[index, 'punctuation_count'] = features.punctuation_count\n",
    "    results.at[index, 'noun_count'] = features.noun_count\n",
    "    results.at[index, 'stopword_count'] = features.stopword_count\n",
    "    results.at[index, 'verb_count'] = features.verb_count\n",
    "    results.at[index, 'adj_count'] = features.adjective_count\n",
    "    results.at[index, 'adv_count'] = features.adverb_count\n",
    "    results.at[index, 'complex_sentence_count'] = features.complex_sentence_count\n",
    "    results.at[index, 'question_mark_count'] = features.question_mark_count\n",
    "    results.at[index, 'exclamation_mark_count'] = features.exclamation_mark_count\n",
    "    results.at[index, 'flesch_reading_ease'] = features.flesch_reading_ease\n",
    "    results.at[index, 'gunning_fog_index'] = features.gunning_fog_index\n",
    "    results.at[index, 'first_person_pronoun_count'] = features.first_person_pronoun_count\n",
    "    results.at[index, 'person_entity_count'] = features.person_entity_count\n",
    "    results.at[index, 'date_entity_count'] = features.date_entity_count\n",
    "    uniqueness_bigram_val, uniqueness_trigram_val = features.calculate_uniqueness_stanza\n",
    "    results.at[index, 'uniqueness_bigram'] = uniqueness_bigram_val\n",
    "    results.at[index, 'uniqueness_trigram'] = uniqueness_trigram_val\n",
    "    results.at[index, 'syntax_variety'] = features.calculate_syntax_variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
